# See more: https://github.com/huggingface/nn_pruning/blob/main/nn_pruning/patch_coordinator.py#L54
distil_alpha_ce: 0.1
distil_alpha_teacher: 0.9
mask_scores_learning_rate: 0.01
initial_warmup: 1
final_warmup: 10
initial_threshold: 0
final_threshold: 0.1
dense_pruning_method: sigmoied_threshold:1d_alt
dense_block_rows: 1
dense_block_cols: 1
attention_pruning_method: sigmoied_threshold
attention_block_rows: 32
attention_block_cols: 32
attention_lambda: 1.0
mask_init: constant
mask_scale: 0.0
regularization: l1
attention_output_with_dense: 0
layer_norm_patch_steps: 50000  # but layer_norm_patch=False by dafault
gelu_patch_steps: 50000   # but gelu_patch=False by default
linear_min_parameters: 0
